# 软件工程硕士论文评价系统全量开发规范
本规范整合系统开发的**技术环境、架构设计、数据流向、数据库、API交互、智能体开发、业务逻辑、平台开发、交付标准**等全维度要求，为各开发小组提供统一执行准则，保障系统开发的一致性、兼容性与可维护性。

## 一、通用技术环境规范
所有开发小组需严格遵循统一技术栈与开发原则，保证环境一致性，降低系统集成成本。
1. **基础开发配置**
    - 编程语言：Python 3.10.x
    - 开发工具：推荐VSCode / PyCharm
    - 依赖管理：需生成精准的`requirements.txt`，指定依赖库版本
2. **核心技术框架**
    - Web框架：FastAPI（**必须支持async异步处理**，禁止阻塞式开发）
    - 数据模型：Pydantic V2（强制实现入参/出参的类型校验）
    - 并发请求：使用httpx / aiohttp，**严禁使用阻塞型requests库**
3. **核心开发原则**
    - 单一职责：每个Agent仅负责指定审计维度（格式/逻辑/代码等），不跨维度处理任务；
    - 无状态设计：Agent不依赖本地持久化存储，所有输入均来自计划中枢组Orchestrator；
    - 格式至上：所有API的输入输出必须100%符合JSON Schema规范，不符合则视为接入失败。

## 二、系统架构与宏观数据流向规范
系统采用**分布式多智能体架构**，整体遵循**四层闭环数据流向**，由计划中枢组统一调度，各小组按流程完成数据处理与审计。
### 1. 四层闭环数据流向
1. **数据摄入层**：用户上传PDF → 中枢组调用MinerU（GPU）将PDF转化为Markdown格式；
2. **结构化层**：中枢组运行Chapter Slicer → 将Markdown全文拆解为摘要/绪论/代码/实验等片段，存入数据库；
3. **分布式审计层**：中枢组通过异步API唤醒2-6组Agent → 各Agent从数据库读取论文片段+从向量库读取专家评语 → 生成JSON格式审计评价；
4. **反思汇总层**：7组（反思评估组）读取2-6组所有JSON结果 → 执行冲突仲裁/幻觉过滤/语意润色 → 生成最终Markdown评审报告。
### 2. 多智能体集群架构原则
- 以**计划中枢智能体**为核心调度节点，所有下游Agent仅与中枢组交互，不直接跨组通信；
- 2-6组为**专项审计智能体**，各司其职完成维度化审计；7组为**质量校验智能体**，不直接审计论文，仅对其他Agent结果做二次审核；
- 中枢组具备**动态路由能力**，可根据论文类型（算法改进型/系统开发型）自适应调整下游Agent的调用序列。

## 三、数据库设计规范
系统统一采用**PostgreSQL + pgvector**组合，核心数据表设计固定，各小组可按需扩展非核心字段，不可修改核心字段的类型与约束。
### 1. 核心数据表结构
#### （1）论文内容表（paper_sections）
存储拆解后的论文各章节结构化Markdown数据，为审计提供原文依据。
|字段|类型|说明|
|---|---|---|
|paper_id|UUID|论文全局唯一标识|
|section_name|String|章节名（abstract/intro/methodology/code/experiment等）|
|content|Text|Markdown格式的章节原始文本|

#### （2）专家知识库（expert_comments）
存储专家评语及向量特征，为各Agent的语义检索提供数据支撑。
|字段|类型|说明|
|---|---|---|
|comment_id|String|评语唯一ID|
|metric_id|String|关联的评价指标ID|
|text|Text|专家原始评语内容|
|embedding|Vector(768)|SBERT生成的向量，用于语义相似度检索|

#### （3）任务协同表（review_tasks）
系统核心交互表，存储所有Agent的审计任务状态、结果、性能数据，支持全局任务监控与结果汇总。
|字段名|类型|约束|说明|
|---|---|---|---|
|id|BigSerial|Primary Key|自增主键，物理存储排序|
|task_id|String/UUID|Indexed|对应上传request_id，追踪单次请求|
|paper_id|UUID|Indexed|关联论文ID，拉取单论文所有审计结果|
|chunk_id|String|-|切片ID，精确定位论文问题位置|
|agent_name|String|-|负责审计的Agent名称|
|agent_version|String|-|审计时的模型/逻辑版本，支持效果回测|
|status|Enum|Default: PENDING|任务状态：PENDING/RUNNING/SUCCESS/FAILED/TIMEOUT|
|score|Integer|-|从result_json冗余的分数，用于统计排名|
|audit_level|String|-|风险等级：Info/Warning/Critical，快速筛选高危问题|
|result_json|JSONB|-|Agent返回的完整原始数据（含comment/suggestion/tags等）|
|error_msg|Text|-|任务失败时，记录错误堆栈/原因|
|usage_tokens|Integer|-|统计单次任务Token消耗|
|latency_ms|Integer|-|记录任务耗时，监控性能瓶颈|
|created_at|Timestamp|Default: Now|任务创建时间|
|updated_at|Timestamp|Default: Now|任务最后一次状态变更时间|
### 2. 数据库操作要求
1. 所有数据库操作需使用**异步驱动**，与FastAPI异步架构匹配，避免阻塞；
2. `paper_id/task_id/chunk_id`需保证全局唯一，与论文上传、切片拆解环节严格关联；
3. 向量检索仅基于pgvector执行，SBERT向量维度固定为768，不可修改；
4. 各Agent完成审计后，需**实时写入/更新review_tasks表**，确保状态与结果数据的时效性。

## 四、API交互规范
系统基于FastAPI实现异步API交互，所有审计Agent组（2-6组）需遵循统一的接口协议，输入输出JSON格式需完全匹配，无值字段填`null`。
### 1. 核心交互协议
#### （1）论文切片上传协议（Orchestrator → Agent）
中枢组向各Agent推送审计任务的统一入参格式，包含任务元数据、论文片段、模型配置。
```json
{
  "request_id": "req_20231027_001",
  "metadata": {
    "paper_id": "uuid-string",
    "paper_title": "论文标题",
    "chunk_id": "chunk_seq_005"
  },
  "payload": {
    "content": "论文切片内容",
    "context_before": "前一段落摘要",
    "context_after": "后一段落开头"
  },
  "config": {
    "temperature": 0.1,
    "max_tokens": 500
  }
}
```
#### （2）审计结果返回协议（Agent → Orchestrator）
各Agent完成审计后，向中枢组返回结果的统一出参格式，包含任务标识、Agent信息、审计结果、资源消耗。
```json
{
  "request_id": "req_20231027_001",
  "agent_info": {
    "name": "Methodology_Agent",
    "version": "v1.2"
  },
  "result": {
    "score": 85,
    "audit_level": "Warning",
    "comment": "审计评语内容",
    "suggestion": "修改建议内容",
    "tags": ["标签1", "标签2"]
  },
  "usage": {
    "tokens": 120,
    "latency_ms": 1500
  }
}
```
### 2. 接口开发要求
1. 所有接口均需定义为**异步接口**（`async def`），符合FastAPI异步规范；
2. 需基于Pydantic V2实现**入参/出参强制校验**，拒绝非法参数请求；
3. 接口需返回**标准HTTP状态码**：成功200、参数错误400、服务异常500；
4. 需记录接口调用的Token消耗、耗时等数据，并同步至`review_tasks`表对应字段。

## 五、各智能体专项开发规范
7个智能体小组需遵循通用规范，同时结合自身审计维度，实现专属核心逻辑、技术栈与字段设计，核心Python库固定不可替换，各小组开发重点与审计要求如下。

### 1. 计划中枢组（Lead Orchestrator Agent）
- **核心Python库**：LangGraph / Flask
- **开发重点**：编写全局任务“状态机”、开发动态路由逻辑，根据论文类型自适应调整下游Agent调用序列；优化全局决策Prompt，实现任务分解、状态管理、接口统一。
- **核心职责**：全局任务调度、审计流程管控、向逻辑审计组注入**全局锚点**（核心假设/主要论点/实验结论）、系统全流程集成。
- **关键要求**：需保证任务调度的高可用性，支持批量论文（1000+）的审计状态管理。

### 2. 格式审计组（Standardization Auditor Agent）
- **核心Python库**：PyMuPDF / OpenCV
- **开发重点**：利用PDF解析技术提取元素坐标，结合计算机视觉（CV）分析PDF布局，核查图表/公式位置，将视觉排版转化为文本逻辑规则。
- **核心审计维度**：引用一致性、图表标号与引用、标题层级、术语一致性、公式规范、标点符号中英文混用、列表符号统一。
- **专属配置**
  - System Prompt：定位为“严苛的期刊排版编辑”，重点扫描排版细节错误；
  - 专属tags：`["Citation_Inconsistency", "Label_Missing", "Punctuation_Error", "Hierarchy_Fault"]`；
- **技术要求**：需实现图表标题位置（图下/表上）、公式编号右对齐等视觉规范的自动化检测。

### 3. 逻辑审计组（Deep Logic Auditor Agent）
- **核心Python库**：Transformers (NLI)
- **开发重点**：利用自然语言推理（NLI）构建论文语义图谱，提取关键句对比摘要与实验数据的语义矛盾，实现“长短期记忆”审计。
- **核心审计逻辑**：全局锚点注入 → 切片微观审计 → 证据追溯，识别论证跳跃、因果倒置、矛盾陈述、无支撑论点。
- **专属配置**
  - 输入策略：采用**三段式输入**（Header=摘要+Window=上下文+切片+Tail=历史逻辑疑点），避免断章取义；
  - 专属tags：`["Logic_Leap", "Circular_Reasoning", "Contradictory_Claim", "Unsupported_Arg"]`；
  - System Prompt：定位为“IEEE/Nature资深审稿人”，仅关注逻辑问题，忽略拼写/代码错误。

### 4. 代码审计组（GraphCode Agent）
- **核心Python库**：NetworkX / Tree-sitter
- **开发重点**：构建存储库智能图谱（RIG）、解析代码依赖，将论文描述的架构图与实际代码调用链路对齐，在非运行环境下发现代码逻辑漏洞。
- **核心审计维度**：代码语法/规范性、算法合理性、注释匹配度、架构实现一致性、性能风险（无限循环/显存溢出）、抄袭风险。
- **专属配置**
  - 模型选择：优先使用对代码敏感的模型（Claude 3.5 Sonnet / DeepSeek Coder）；
  - 专属字段：可添加`location`字段标注问题行号，tags为`["Syntax_Error", "Logic_Flaw", "Performance_Issue", "Plagiarism_Risk"]`；
  - System Prompt：定位为“高级算法工程师”，重点检查变量初始化、张量形状对齐、算法复杂度与论文宣称的一致性。

### 5. 实验数据组（Empirical Data Agent）
- **核心Python库**：Pandas / Scipy
- **开发重点**：利用统计学模型评估结论显著性，结合图像取证技术识别图表数据异常/伪造，核查实验设置的科学性。
- **核心审计维度**：统计有效性（样本量/P值）、图表数据一致性、实验设置合理性（基准/消融实验/对照组）、数据异常点、性能提升夸大。
- **专属配置**
  - 专属tags：`["Statistical_Weakness", "Data_Inconsistency", "Baseline_Missing"]`；
  - System Prompt：定位为“精通统计学的审稿专家”，重点检查误差棒/标准差缺失、实验环境描述模糊、数据支撑力弱等问题。

### 6. 文献真实性组（Citation Integrity Agent）
- **核心Python库**：FAISS / Requests
- **开发重点**：通过RAG技术对接IEEE/Google Scholar等权威数据库API，实时比对引文真实性，解决LLM“幻觉引用”问题，无API时先实现内部逻辑校验。
- **核心审计维度**：文献真实性（作者/年份/篇名）、引用关联性、时效性（近3-5年文献）、引用格式规范性。
- **专属配置**
  - 专属字段：可添加`evidence`字段标注检索结果，tags为`["Fake_Reference", "Outdated_Source", "Misinterpretation"]`；
  - System Prompt：定位为“学术打假专家”，对伪造文献、领域不匹配引用标记为Critical，要求作者提供DOI/链接。

### 7. 反思评估组（Self-Reflection Judge Agent）
- **核心Python库**：OpenAI API / LiteLLM
- **开发重点**：编写高质量Judge Prompt，利用LLM-as-a-judge模式分析其他Agent的客观性，纠正模型幻觉，实现审计结果的整合与润色。
- **核心职责**：冲突裁决、重复过滤、审计建议优先级排序、论文综合评分、按导师习惯编排评审报告，**不直接审计论文**。
- **专属配置**
  - 输入差异：payload.content为其他Agent返回的JSON集合，非论文片段；
  - 专属字段：可添加`final_verdict`字段给出论文最终定性（如“建议大修后录用”），tags为`["Executive_Summary", "Critical_Fix_List", "Score_Calibration"]`。

## 六、核心业务逻辑规范
系统业务逻辑分为**审计Agent通用逻辑**（2-6组）与**反思评估组专属逻辑**（7组），各小组需严格遵循，保证审计结果的客观性、准确性与逻辑性。

### 1. 2-6组审计Agent通用业务逻辑
所有专项审计Agent内部需遵循**三步闭环逻辑**，确保评价结果有原文依据、有专家话术支撑：
1. **事实提取**：利用LLM提取论文切片中的关键数值、主张、架构、实验设置等核心事实；
2. **语义检索**：使用SBERT计算“事实描述”与`expert_comments`表中向量的相似度，拉取最匹配的专家评语；
3. **评价生成**：将原文证据、评价指标要求、专家话术喂给LLM，生成带证据、有依据的最终审计评语。

### 2. 7组反思评估组专属业务逻辑
作为系统质量保险层，需遵循**四步核心逻辑**，将碎片化审计结果转化为连贯的评审报告：
1. **一致性校验**：检查各审计Agent的结果是否存在矛盾（如格式组说“图表清晰”，代码组说“架构图缺失”），并给出最终裁决；
2. **幻觉过滤**：核实各Agent返回的证据引语是否真实存在于`paper_sections`表的论文原文中；
3. **结果整合**：对审计建议做重复过滤、按“修改必要性”优先级排序；基于各组score计算论文综合得分；
4. **报告编排**：按照导师评审习惯，将碎片化的审计发现串联成起承转合自然的Markdown评审意见书。

## 七、平台开发规范
系统需在算法基础上开发**前端交互+后端业务**模块，实现从“算法”到“平台”的落地，支持人工复核与系统管理，核心技术栈与功能要求如下。

### 1. 前端开发规范
- **技术栈**：React + Tailwind CSS
- **核心开发要求**
  1. 开发**交互式评审界面**：左右分屏设计，左侧展示MinerU解析后的Markdown原文，右侧展示AI审计建议；
  2. 实现**锚点定位功能**：点击右侧“证据”，左侧原文自动滚动并高亮对应的错误段落/图表/公式；
  3. 开发定制化**Markdown渲染器**：支持关键词高亮、锚点跳转、论文元素（图表/公式）的可视化展示。

### 2. 后端开发规范
- **技术栈**：在计划中枢组原有FastAPI基础上扩展业务API
- **核心开发要求**
  1. 新增核心业务API：用户上传API、权限管理API、评审报告导出API、审计状态查询API、Agent参数配置API；
  2. 实现**数据关联逻辑**：通过`paper_id`关联`paper_sections`（左屏原文）与`review_tasks`（右屏评语），支撑前端锚点定位；
  3. 支持**批量数据处理**：满足1000+份论文的审计状态存储、查询与统计。

### 3. 平台核心功能模块
1. **导师复核流程（Human-in-the-loop）**
   - 支持对AI生成的评语进行二次编辑、点击“忽略”误报项；
   - 实现**一键导出**：根据最终修改后的JSON结果，套用学校标准模板生成Word/PDF格式评审表。
2. **管理员看板**
   - 实现**进度监控**：可视化展示1000+份论文的审计状态（已完成/进行中/异常）；
   - 实现**指标优化**：支持通过Web界面调整各Agent的Prompt、评价指标权重，无需修改代码；
   - 实现**性能监控**：展示各Agent的Token消耗、耗时（latency_ms），定位性能瓶颈。

## 八、交付标准规范
所有开发小组完成开发后，需按统一格式交付成果，**交付物缺一不可**，确保系统集成的高效性与后期维护的便捷性。
1. **源码**：按功能模块划分目录，代码添加规范注释，目录结构清晰，无冗余代码；
2. **requirements.txt**：记录所有依赖库及**精确版本号**，避免版本冲突，可直接通过`pip install`安装；
3. **Dockerfile**：编写标准化Dockerfile，指定基础镜像为Python 3.10.x，支持容器化部署，可直接构建镜像并运行；
4. **开发文档**：包含模块功能、接口说明、核心业务逻辑、配置方法、性能测试报告；
5. **测试用例**：提供单元测试、接口测试、功能测试用例，覆盖核心功能，**测试通过率需达到100%**；
6. **版本管理说明**：记录Agent版本号（按vX.X格式命名），版本更新内容需同步至`review_tasks`表的`agent_version`字段，支持效果回测。